{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity - Machine Learning Engineer Nanodegree Program\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project\n",
    "Matheus Sena Vasconcelos  \n",
    "Fevereiro 26st, 2020\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.I. Project Overview\n",
    "\n",
    "<p style='text-align: justify; text-indent: 40px;'>\n",
    "    RMS Titanic was designed to be the more luxurious and safest ship built in 20th century. On the night of April 20, the Titanic hit an iceberg and sink in the middle on its journey. Unfortunately, due to the low number of rescue boats, more than a half of the passengers have died. The survive number was only 722 of 2224 in total.\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify; text-indent: 40px;'>\n",
    "    The project proposal is to build a predictor model that recieves, as input, passenger information (like name, age, gender, socio-economic and class) and return if this fictitious passenger would survive or not in Titanic tragedy. To go further and receive theses passenger information, an endpoint will be develop using Python Frameworks in order to demonstrate another away to create endpoints, instead of those shown during the Nanodegree Program using AWS.\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.II. Problem Statement\n",
    "\n",
    "<p style='text-align: justify; text-indent: 40px;'>\n",
    "    The problem is Kaggle challenge and can be access <a href=\"https://www.kaggle.com/c/titanic\">here</a>. Based on the passenger data, the challenge is to build a predictive model that answers the question: \n",
    "</p>\n",
    "\n",
    ">  “what sorts of people were more likely to survive?”\n",
    "\n",
    "<p style='text-align: justify; text-indent: 40px;'>\n",
    "    In others words. The idea is to use the provided dataset, which contains all informations about the passenger aboard Titanic in 1912, and build a machine learning model that predicts if the passenger would survive, based on new data received.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.III. Datasets and Inputs\n",
    "\n",
    "<p style='text-align: justify; text-indent: 40px;'>\n",
    "    As it was mentioned above, the dataset was provided by Kaggle on a machine learning competition. The original dataset can be downloaded <a href=\"https://www.kaggle.com/c/titanic/data\">here</a> and comes with 3 files:\n",
    "</p>\n",
    "\n",
    "* __train.csv__ - file which contains data that have to use as model training input.\n",
    "* __test.csv__ - file which contains data to check the accuracy of the model created.\n",
    "* __gender_submission.csv__ - file which contains examples of what a submission file should look like. This file will not be used.\n",
    "\n",
    "<p style='text-align: justify; text-indent: 40px;'>\n",
    "    All features in the dataset in based on passenger informations, and they are described below.\n",
    "</p>\n",
    "\n",
    "* __PassengerId__ - a unique value to identify the passenger (integer).\n",
    "* __Survived__ - indicates if the passenger survived or not (integer).\n",
    "* __Name__ - passenger name (string).\n",
    "* __Pclass__ - passenger ticket class (interger).\n",
    "* __Sex__ - passenger sex (string).\n",
    "* __Age__ - passenger ager (integer).\n",
    "* __SibSp__ - number of passenger siblings and spouses aboard (integer).\n",
    "* __Parch__ - number of passenger parents / children aboard (integer).\n",
    "* __Ticket__ - passenger ticket number (string).\n",
    "* __Fare__ - paid fare (float).\n",
    "* __Cabin__ - passenger cabin number (string).\n",
    "* __Embarked__ - port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.IV. Solution Statement\n",
    "\n",
    "<p style='text-align: justify; text-indent: 40px;'>\n",
    "    The solution is a classification model that predicts if the passenger would survive based on the passenger information. To make predictions through HTTP requests, an endpoint will be developed using Python Frameworks. Before modeling the predictor, python libraries like Numpy, Pandas and Matplotlib will be used to data visualization and data preprocessing. Then, the model will be built using Sklearn Estimators and Sklearn Metrics Functions to measure model quality. Lastly, Python Flask and Docker will be used to create an endpoint to access the model and make predictions.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.V. Benchmark Model\n",
    "\n",
    "<p style='text-align: justify; text-indent: 40px;'>\n",
    "    First, it will be user Sklearn Estimator without any special parameters (default hyperparameters). Then, to compare the results, a grid search model selection will be used to select the same model with betters hyperparameters and compare with the default model.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.VI. Evaluation Metrics\n",
    "\n",
    "<p style='text-align: justify; text-indent: 40px;'>\n",
    "    For the model evaluation, a accuracy score and confusion matrix will be used.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.VII. Project Design\n",
    "\n",
    "#### Data visualization\n",
    "* this is the step to get more information about the dataset, visualizing them.\n",
    "\n",
    "#### Data preprocessing\n",
    "* fill empty rows with median (or other metrics).\n",
    "* remove remaining empty rows.\n",
    "* encode non-numerical features, if necessary.\n",
    "* remove remaining non-numerical features.\n",
    "* normalize numerical features with MinMaxNormalization.\n",
    "* balance data per target class.\n",
    "\n",
    "#### Data splitting\n",
    "* split the train.csv dataset into 85% for training and 15% for testing.\n",
    "* __OBS:__ the test.csv file will be used to evaluation.\n",
    "\n",
    "#### Model selection\n",
    "* training different kind of Estimator with default hyperparameters.\n",
    "* choose the best one\n",
    "\n",
    "#### Hyperparameter tuning\n",
    "* using grid search to select the best hyperparameter.\n",
    "\n",
    "#### Endpoint\n",
    "* create an REST API to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
